# 使用到的模型列表

嵌入模型：bge-m3
重排序模型：bge-reranker-v2-m3
回答生成大模型：qwen-plus(api)
query改写大模型：qwen2.5-72b-instruct

# 数据
数据方面采用的是tugraph github网站上的userdoc的md文档+issuses+FAQ+少量的tugraph公众号数据
并且对于所有数据我们都使用了专门的方法进行了结构化处理，使其全部解析为md文档便于形式结构化知识库。

# 实现方案（检索+生成）

## 检索
sft步骤
首先我们对用户输入的问题做了了改写，针对用户问题的常见错误进行了矫正，使得问题更加清晰便于后续检索。

召回部分我们的基础采用了主流的混合检索模式:向量检索+关键字检索，其中我们对向量检索进行了优化，传统的向量检索不能很好的解决中英问题向量的差别，所以我们采用了中英向量混合检索来召回更多的候选节点。关键字检索使用了BM25算法，但由于BM25Retriever不支持中文所以我们对他进行了重写以适配中文。并最终依照重要性对这三种检索模式附上权重。

重排序部分我们对候选节点经行了精排筛选出5个最相似的节点送入上下文进行回答。

## 生成
为了使得模型回答的结果更加贴近标签，我们采用了动态示例（dynamic few-shot）的方法让大模型能够按照要求进行输出。具体来说我们首先对带标签的数据集val.jsonl进行了风格标注（使用gpt-4o完成），将这50条数据的问题和答案依次输给4o让其总结归纳每道题的答题风格，然后对于测试集上的每一道问题，我们都对其进行相似度匹配，选出相似度最高的几道问题，把他们的问题、答案以及表注风格展示给大模型，要求他按照示例的风格进行输出。
最后由于模型生成的随机性，以及上下文的长文本性，模型在某些情况下可能不能很好地执行风格化输出，我们又对输出的结果进行了后处理。